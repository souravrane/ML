{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(dataset, train_per = 0.67 , test_per = 0.33):\n",
    "    np.random.shuffle(dataset)\n",
    "    n = len(dataset)\n",
    "    train_n = int(n*train_per)\n",
    "    train = dataset[:train_n,:]\n",
    "    test = dataset[train_n:,:]\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process(train):\n",
    "    (nr,nc) = train.shape\n",
    "    ncls = int(max(train[:,-1]))+1\n",
    "    \n",
    "    avg = np.zeros((nc,ncls))\n",
    "    var = np.zeros((nc,ncls))\n",
    "    class_prob = np.zeros((ncls))\n",
    "    \n",
    "    for cls in range(ncls):\n",
    "        ind = (train[:,-1] == cls)\n",
    "        subset = train[ind]\n",
    "        class_prob[cls] = len(subset)\n",
    "        avg[:,cls] = np.mean(subset,axis=0)\n",
    "        var[:,cls] = np.var(subset,axis=0)\n",
    "        \n",
    "    class_prob = class_prob / len(train)\n",
    "    \n",
    "    return avg,var,class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gauss(x,mu,var):\n",
    "    return (math.exp(-(-x-mu)**2/(2*var))/(math.sqrt(2*var*math.pi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.00000000e+00   1.13000000e+02   4.40000000e+01 ...,   1.40000000e-01\n",
      "    2.20000000e+01   0.00000000e+00]\n",
      " [  3.00000000e+00   1.26000000e+02   8.80000000e+01 ...,   7.04000000e-01\n",
      "    2.70000000e+01   0.00000000e+00]\n",
      " [  1.10000000e+01   1.38000000e+02   7.40000000e+01 ...,   5.57000000e-01\n",
      "    5.00000000e+01   1.00000000e+00]\n",
      " ..., \n",
      " [  1.00000000e+00   1.22000000e+02   9.00000000e+01 ...,   3.25000000e-01\n",
      "    3.10000000e+01   1.00000000e+00]\n",
      " [  0.00000000e+00   1.73000000e+02   7.80000000e+01 ...,   1.15900000e+00\n",
      "    5.80000000e+01   0.00000000e+00]\n",
      " [  4.00000000e+00   1.20000000e+02   6.80000000e+01 ...,   7.09000000e-01\n",
      "    3.40000000e+01   0.00000000e+00]]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.  1.  0.\n",
      "  1.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.  0.\n",
      "  0.  1.  1.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.  0.\n",
      "  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.  0.  0.  1.  0.\n",
      "  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.\n",
      "  1.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  0.  0.  0.  1.  0.  1.\n",
      "  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.\n",
      "  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.]\n",
      "254 [0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0]\n",
      "0.57874015748\n"
     ]
    }
   ],
   "source": [
    "dataset = np.array(pd.read_csv('diabetes.csv'))\n",
    "train,test = split_data(dataset)\n",
    "avg,var,class_prob = pre_process(train)\n",
    "pred = []\n",
    "print(train)\n",
    "print(test[:,-1])\n",
    "\n",
    "(nr,nc) = test.shape\n",
    "(_,ncls) = var.shape\n",
    "\n",
    "for r in range(nr):\n",
    "    cls = train[r,-1]\n",
    "    prob_list = []\n",
    "    for cls in range(ncls):\n",
    "        prob = 1\n",
    "        for c in range(nc-1):\n",
    "            prob*=gauss(test[r,c] , avg[c,cls] , var[c,cls])\n",
    "        prob_list.append(prob)\n",
    "    prediction = prob_list.index(max(prob_list))\n",
    "    pred.append(prediction)\n",
    "print(len(pred),pred)\n",
    "print(np.sum(pred == test[:,-1])/nr)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
